{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e403fec8",
   "metadata": {},
   "source": [
    "HTML Data Extraction\n",
    "\n",
    "source: H&M <https://www2.hm.com/en_us/men/products/jeans.html>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e19ec2c",
   "metadata": {},
   "source": [
    "Data to be collected for table creation:\n",
    "\n",
    "- product_id\n",
    "- product_name\n",
    "- product_type\n",
    "- product_color\n",
    "- composition\n",
    "- price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf4cf37",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4542d0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "\n",
    "import requests\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import math\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf35299b",
   "metadata": {},
   "source": [
    "## Collect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9b8d800",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_type</th>\n",
       "      <th>product_price</th>\n",
       "      <th>scrapy_datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1074475001</td>\n",
       "      <td>Loose Jeans</td>\n",
       "      <td>ladies_sport_sportaccessories</td>\n",
       "      <td>$ 39.99</td>\n",
       "      <td>2022-06-10 10:24:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1071707001</td>\n",
       "      <td>Relaxed Jeans</td>\n",
       "      <td>ladies_sport_sportaccessories</td>\n",
       "      <td>$ 29.99</td>\n",
       "      <td>2022-06-10 10:24:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1024256001</td>\n",
       "      <td>Slim Jeans</td>\n",
       "      <td>ladies_sport_sportaccessories</td>\n",
       "      <td>$ 19.99</td>\n",
       "      <td>2022-06-10 10:24:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0985159001</td>\n",
       "      <td>Skinny Jeans</td>\n",
       "      <td>ladies_sport_sportaccessories</td>\n",
       "      <td>$ 19.99</td>\n",
       "      <td>2022-06-10 10:24:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1004199004</td>\n",
       "      <td>Skinny Cropped Jeans</td>\n",
       "      <td>ladies_sport_sportaccessories</td>\n",
       "      <td>$ 29.99</td>\n",
       "      <td>2022-06-10 10:24:10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id          product_name                   product_type  \\\n",
       "0  1074475001           Loose Jeans  ladies_sport_sportaccessories   \n",
       "1  1071707001         Relaxed Jeans  ladies_sport_sportaccessories   \n",
       "2  1024256001            Slim Jeans  ladies_sport_sportaccessories   \n",
       "3  0985159001          Skinny Jeans  ladies_sport_sportaccessories   \n",
       "4  1004199004  Skinny Cropped Jeans  ladies_sport_sportaccessories   \n",
       "\n",
       "  product_price      scrapy_datetime  \n",
       "0       $ 39.99  2022-06-10 10:24:10  \n",
       "1       $ 29.99  2022-06-10 10:24:10  \n",
       "2       $ 19.99  2022-06-10 10:24:10  \n",
       "3       $ 19.99  2022-06-10 10:24:10  \n",
       "4       $ 29.99  2022-06-10 10:24:10  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Browser camouflage for website request (parameters)\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}\n",
    "\n",
    "# Website URL for all men's jeans\n",
    "url1 = 'https://www2.hm.com/en_us/men/products/jeans.html'\n",
    "\n",
    "# Request to URL\n",
    "page = requests.get( url1, headers=headers )\n",
    "\n",
    "# Returning the page's HTML\n",
    "page.text\n",
    "\n",
    "# Instantiating Beautiful Soup object\n",
    "soup = BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "#============================================= Product Data =============================================\n",
    "# HTML structure where the showcase is stored\n",
    "products = soup.find('ul', class_ = 'products-listing small')\n",
    "\n",
    "#  HTML Structure (Class) where all data (data-articlecode and data-category) is stored\n",
    "product_list = products.find_all('article', class_= 'hm-product-item')\n",
    "\n",
    "# Returning first element of product_list\n",
    "product_list[1]\n",
    "\n",
    "# Number of items in the product_list\n",
    "len(product_list)\n",
    "\n",
    "#============================================= product_id =============================================\n",
    "\n",
    "# Returned first item from  data-articlecode (product_id) items from product_list\n",
    "product_list[0].get('data-articlecode')\n",
    "\n",
    "# Looping to collect all data-articlecode (product_id) items from product_list\n",
    "product_id = [p.get('data-articlecode') for p in product_list]\n",
    "product_id\n",
    "\n",
    "#============================================= product_type =============================================\n",
    "\n",
    "# Returned first item from  data-category (product_type) items from product_list\n",
    "product_list[0].get('data-category')\n",
    "\n",
    "# Looping to collect all data-category (product_type) items from product_list\n",
    "product_type = [p.get('data-category') for p in product_list]\n",
    "product_type\n",
    "\n",
    "#  HTML structure (class) where the data (product_name) is stored\n",
    "product_list = products.find_all('a', class_='link')\n",
    "product_list\n",
    "\n",
    "#============================================= product_name =============================================\n",
    "\n",
    "# Returning the first item (product_name) from the product_list list data\n",
    "product_list[0].get_text()\n",
    "\n",
    "# Looping to collect all data (product_name) items from product_list\n",
    "product_name = [p.get_text() for p in product_list]\n",
    "product_name\n",
    "\n",
    "#  HTML structure (class) where the data (product_price) is stored\n",
    "product_list = products.find_all('span', class_='price regular')\n",
    "product_list\n",
    "\n",
    "#============================================= product_price =============================================\n",
    "\n",
    "# Returning the first item (product_price) from the product_list list data\n",
    "product_list[0].get_text()\n",
    "\n",
    "# Looping to collect all data (product_price) items from product_list\n",
    "product_price = [p.get_text() for p in product_list]\n",
    "product_price\n",
    "\n",
    "#============================================= Data Frame =============================================\n",
    "# DataFrame creation\n",
    "data = pd.DataFrame([product_id,\n",
    "              product_name,\n",
    "              product_type,\n",
    "              product_price,]).T\n",
    "\n",
    "# Rename colomns DataFrame\n",
    "data.columns = ['product_id',\n",
    "                'product_name',\n",
    "                'product_type',\n",
    "                'product_price']\n",
    "\n",
    "# Irregular date and time setting\n",
    "data['scrapy_datetime'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756dc5e5",
   "metadata": {},
   "source": [
    "## Pagination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705d12a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pagination: Returning all site pages\n",
    "#soup.find_all('h2', class_='load-more-heading')\n",
    "\n",
    "# Returning all products from all pages on the site\n",
    "#total_item = soup.find_all('h2', class_='load-more-heading')[0].get('data-total')\n",
    "#total_item\n",
    "\n",
    "# Transforming into integer to know how many pages I need\n",
    "# Ex: 36 products fit per page, so I need 2.41 pages\n",
    "#int(total_item)/36\n",
    "\n",
    "# Rounding the values to know how many pages I need\n",
    "#page_number = math.ceil(int(total_item)/36)\n",
    "#page_number\n",
    "\n",
    "# Rounding off values (another way to do it)\n",
    "#page_number = np.round(int(total_item)/36)\n",
    "#page_number\n",
    "\n",
    "# Secondary url with all products from all site pages\n",
    "#url02 = url1 + '?pagesize=' + str(int(page_number*36))\n",
    "#url02"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed0cbb4",
   "metadata": {},
   "source": [
    "# One product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e80eaf5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Browser camouflage for website request\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}\n",
    "\n",
    "# Website url for just one product\n",
    "url = 'https://www2.hm.com/en_us/productpage.1024256001.html'\n",
    "#print(url)\n",
    "\n",
    "# Request\n",
    "page = requests.get( url, headers=headers )\n",
    "\n",
    "# Returning the page's HTML\n",
    "page.text\n",
    "\n",
    "# Instantiating Beautiful Soup object\n",
    "soup = BeautifulSoup(page.text, 'html.parser')\n",
    "soup\n",
    "type(soup)\n",
    "\n",
    "# HTML Structure (Class) where all data is stored\n",
    "soup.find_all('li', class_='list-item')\n",
    "\n",
    "# Returning the first elements of the list item\n",
    "soup.find_all('li', class_='list-item')[0]\n",
    "\n",
    "#============================================= Color Name =============================================\n",
    "\n",
    "# HTML structure (Class) where color data is stored\n",
    "soup.find_all('a', class_='filter-option miniature active')[0]\n",
    "soup.find_all('a', class_='filter-option miniature active')[0].get('data-color')\n",
    "\n",
    "\n",
    "product_atributes_list = soup.find_all('a', {'class':['filter-option miniature', 'filter-option miniature active']})\n",
    "color_name = [p.get('data-color') for p in product_atributes_list]\n",
    "color_name\n",
    "\n",
    "# Looping para coleta de todos os itens product_id_c da lista product_atributes_list\n",
    "product_id_c = [p.get('data-articlecode') for p in product_atributes_list]\n",
    "product_id_c\n",
    "\n",
    "# DataFrame creation\n",
    "df_color = pd.DataFrame([product_id_c, color_name]).T\n",
    "df_color\n",
    "\n",
    "# Rename colomns DataFrame\n",
    "df_color.columns = ['product_id', 'color_name']\n",
    "\n",
    "df_color.head()\n",
    "\n",
    "# Generate Style id + Color id\n",
    "df_color['style_id'] = df_color['product_id'].apply(lambda x: x[:-3])\n",
    "df_color['color_id'] = df_color['product_id'].apply(lambda x: x[-3:])\n",
    "df_color\n",
    "\n",
    "#============================================= Composition =============================================\n",
    "\n",
    "# HTML structure where the all data is stored:\n",
    "soup.find_all('div', class_='details-attributes-list-item')\n",
    "\n",
    "# Returning the first elements of the list item\n",
    "soup.find_all('div', class_='details-attributes-list-item')[0]\n",
    "soup.find_all('div', class_='details-attributes-list-item')[0].get_text()\n",
    "\n",
    "# HTML structure (Class) where composition data is stored\n",
    "product_composition_list = soup.find_all('div', class_='details-attributes-list-item')\n",
    "\n",
    "# Looping to collect all product_composition items from the product_attributes_list list\n",
    "product_composition = [list(filter(None, p.get_text().split('\\n'))) for p in product_composition_list]\n",
    "product_composition\n",
    "\n",
    "# DataFrame creation\n",
    "df_composition = pd.DataFrame(product_composition).T\n",
    "df_composition\n",
    "\n",
    "# Rename colomns DataFrame\n",
    "df_composition.columns = df_composition.iloc[0]\n",
    "df_composition\n",
    "\n",
    "# Delete First row\n",
    "df_composition = df_composition.iloc[1:].fillna(method='ffill')\n",
    "df_composition\n",
    "\n",
    "# Generate Style id + Color id\n",
    "df_composition['style_id'] = df_composition['Art. No.'].apply(lambda x: x[:-3])\n",
    "df_composition['color_id'] = df_composition['Art. No.'].apply(lambda x: x[-3:])\n",
    "\n",
    "# Merge Data Color + Data Composition\n",
    "data_color_composition = pd.merge(df_color, df_composition[['style_id','Fit','Composition']] , how='left', on='style_id')\n",
    "data_color_composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5770b5fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.head()\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5f2708",
   "metadata": {},
   "source": [
    "# Multiple Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f154e92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Browser camouflage for website request\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}\n",
    "\n",
    "# Empty DataFrame\n",
    "df_details = pd.DataFrame()\n",
    "\n",
    "# Unique columns for all products\n",
    "aux = []\n",
    "\n",
    "set(aux)\n",
    "\n",
    "cols = ['Art. No.',\n",
    " 'Care instructions',\n",
    " 'Composition',\n",
    " 'Concept',\n",
    " 'Description',\n",
    " 'Fit',\n",
    " 'Imported',\n",
    " 'Material',\n",
    " 'Nice to know',\n",
    " 'messages.garmentLength',\n",
    " 'messages.waistRise']\n",
    "\n",
    "df_pattern = pd.DataFrame(columns = cols)\n",
    " \n",
    "# Looping for all products on the site\n",
    "for i in range(len(data)):\n",
    "    #Website url for all products\n",
    "    url_all = 'https://www2.hm.com/en_us/productpage.' + data.loc[i, 'product_id'] +'.html'\n",
    "    #print(url_all)\n",
    "    \n",
    "    # Request\n",
    "    page = requests.get( url, headers=headers )\n",
    "    \n",
    "    # Instantiating Beautiful Soup object\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    \n",
    "    #============================ Color Name =============================\n",
    "    product_atributes_list = soup.find_all('a', {'class':['filter-option miniature', 'filter-option miniature active']})\n",
    "    color_name = [p.get('data-color') for p in product_atributes_list]\n",
    "    \n",
    "    # product id\n",
    "    # Looping para coleta de todos os itens product_id_c da lista product_atributes_list\n",
    "    product_id_c = [p.get('data-articlecode') for p in product_atributes_list]\n",
    "    \n",
    "    # DataFrame creation\n",
    "    df_color = pd.DataFrame([product_id_c, color_name]).T\n",
    "    \n",
    "    # Rename colomns DataFrame\n",
    "    df_color.columns = ['product_id', 'color_name']\n",
    "    \n",
    "    # Generate Style id + Color id\n",
    "    df_color['style_id'] = df_color['product_id'].apply(lambda x: x[:-3])\n",
    "    df_color['color_id'] = df_color['product_id'].apply(lambda x: x[-3:])\n",
    "    \n",
    "    \n",
    "    #============================ Composition =============================\n",
    "    product_composition_list = soup.find_all('div', class_='details-attributes-list-item')\n",
    "    product_composition = [list(filter(None, p.get_text().split('\\n'))) for p in product_composition_list]\n",
    "    \n",
    "    # Rename DataFrame\n",
    "    df_composition = pd.DataFrame(product_composition).T\n",
    "    df_composition.columns = df_composition.iloc[0]\n",
    "    \n",
    "    # Delete First row\n",
    "    df_composition = df_composition.iloc[1:].fillna(method='ffill')\n",
    "    \n",
    "    # garantee the same number of columns\n",
    "    df_composition = pd.concat([df_pattern, df_composition], axis=0)\n",
    "    \n",
    "    # Generate Style id + Color id\n",
    "    df_composition['style_id'] = df_composition['Art. No.'].apply(lambda x: x[:-3])\n",
    "    df_composition['color_id'] = df_composition['Art. No.'].apply(lambda x: x[-3:])\n",
    "    \n",
    "    aux = aux + df_composition.columns.tolist()\n",
    "    \n",
    "    # Merge Data Color + Data Composition\n",
    "    data_color_composition = pd.merge(df_color, df_composition[['style_id','Fit','Composition', 'Material','Description','messages.waistRise']] , how='left', on='style_id')\n",
    "    \n",
    "    # All details products\n",
    "    df_details = pd.concat([df_details, data_color_composition], axis=0)\n",
    "    \n",
    "df_details.head()\n",
    "\n",
    "# Joining the DataFrames: data + details\n",
    "data['style_id'] = data['product_id'].apply(lambda x: x[:-3])\n",
    "data['color_id'] = data['product_id'].apply(lambda x: x[-3:])\n",
    "\n",
    "data_raw = pd.merge(data, df_details[['style_id','color_name','Fit','Composition', 'Description','messages.waistRise']], how='left', on='style_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7a88d4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f75c267",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw.to_csv('data_row.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
